{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed\n",
    "import os\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "sequence_length = 40\n",
    "img_height = 120\n",
    "img_width = 160\n",
    "batch_size = 12\n",
    "folder_name = 'rgb_image_dataset'\n",
    "split_value = 0.1\n",
    "EPOCHS = 200\n",
    "INIT_LR = 0.00001\n",
    "actions = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "PERCENT = 25\n",
    "movements = np.array(['scroll_right', 'scroll_left', 'scroll_up', 'scroll_down', 'zoom_in', 'zoom_out'])\n",
    "\n",
    "\n",
    "def resize_image(img):\n",
    "    width = int(img.shape[1] * PERCENT / 100)\n",
    "    height = int(img.shape[0] * PERCENT / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def landmark_extractor(imagePath):\n",
    "    with mp_holistic.Holistic(static_image_mode=True, min_detection_confidence=0.5,\n",
    "                              min_tracking_confidence=0.5) as holistic:\n",
    "        image = cv2.imread(imagePath)\n",
    "        results = holistic.process(image)\n",
    "        pose = np.array([[res.x, res.y, res.z, res.visibility] for res in\n",
    "                         results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "        lh = np.array([[res.x, res.y, res.z] for res in\n",
    "                       results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(\n",
    "            21 * 3)\n",
    "        rh = np.array([[res.x, res.y, res.z] for res in\n",
    "                       results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(\n",
    "            21 * 3)\n",
    "        return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 'video_landmark_dataset/rgb'\n",
    "label_map = {label: num for num, label in enumerate(movements)}\n",
    "sequences, labels = [], []\n",
    "for movement in movements:\n",
    "    for dirpath, dirnames, files in os.walk(os.path.join(root, movement)):\n",
    "        sequence = []\n",
    "        if len(files) != 0:\n",
    "            for i in range(sequence_length):\n",
    "                res = np.load(os.path.join(dirpath, '{}.npy'.format(i)))\n",
    "                sequence.append(res)\n",
    "        if len(sequence) > 0:\n",
    "            sequences.append(sequence)\n",
    "            labels.append(label_map[movement])\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 40, 258)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vid = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv3D(16, kernel_size=(3, 3, 4), input_shape=(10, 120, 160, 3), strides=(1, 1, 1),\n",
    "                      padding='valid',\n",
    "                      activation='relu'),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.Conv3D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv3D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(6, activation='softmax'),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 37, 64)            66112     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 37, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 18, 64)            24640     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 18, 32)            6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 32)             128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 9, 32)             3104      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 9, 16)             1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 16)             64        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               19500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 176,686\n",
      "Trainable params: 176,590\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 39ms/step - loss: 1.0959 - accuracy: 0.6976 - val_loss: 1.3319 - val_accuracy: 0.6957\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.1186 - accuracy: 0.7171 - val_loss: 1.3355 - val_accuracy: 0.6957\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0948 - accuracy: 0.7610 - val_loss: 1.3352 - val_accuracy: 0.6957\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.1000 - accuracy: 0.7024 - val_loss: 1.3349 - val_accuracy: 0.6957\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0789 - accuracy: 0.7561 - val_loss: 1.3299 - val_accuracy: 0.6957\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0662 - accuracy: 0.7463 - val_loss: 1.3181 - val_accuracy: 0.7391\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0645 - accuracy: 0.7707 - val_loss: 1.3005 - val_accuracy: 0.6522\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0796 - accuracy: 0.7659 - val_loss: 1.2947 - val_accuracy: 0.6957\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0679 - accuracy: 0.7805 - val_loss: 1.2849 - val_accuracy: 0.6087\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0462 - accuracy: 0.7854 - val_loss: 1.2784 - val_accuracy: 0.6087\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0547 - accuracy: 0.7415 - val_loss: 1.2810 - val_accuracy: 0.6087\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0857 - accuracy: 0.7756 - val_loss: 1.2812 - val_accuracy: 0.6522\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0234 - accuracy: 0.7902 - val_loss: 1.2697 - val_accuracy: 0.6522\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0394 - accuracy: 0.7902 - val_loss: 1.2504 - val_accuracy: 0.6522\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0140 - accuracy: 0.7902 - val_loss: 1.2487 - val_accuracy: 0.6522\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0370 - accuracy: 0.7756 - val_loss: 1.2458 - val_accuracy: 0.6522\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0251 - accuracy: 0.7610 - val_loss: 1.2422 - val_accuracy: 0.6957\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9996 - accuracy: 0.7902 - val_loss: 1.2305 - val_accuracy: 0.6957\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9676 - accuracy: 0.7854 - val_loss: 1.2218 - val_accuracy: 0.6522\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0222 - accuracy: 0.7463 - val_loss: 1.2264 - val_accuracy: 0.6522\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9966 - accuracy: 0.7902 - val_loss: 1.2327 - val_accuracy: 0.6522\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9803 - accuracy: 0.7805 - val_loss: 1.2180 - val_accuracy: 0.6957\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9653 - accuracy: 0.7902 - val_loss: 1.1919 - val_accuracy: 0.6522\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9582 - accuracy: 0.8146 - val_loss: 1.1996 - val_accuracy: 0.6957\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9850 - accuracy: 0.7805 - val_loss: 1.2050 - val_accuracy: 0.6522\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9342 - accuracy: 0.8195 - val_loss: 1.1914 - val_accuracy: 0.6087\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9417 - accuracy: 0.8488 - val_loss: 1.1791 - val_accuracy: 0.6522\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9516 - accuracy: 0.8098 - val_loss: 1.1619 - val_accuracy: 0.7391\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9432 - accuracy: 0.7951 - val_loss: 1.1584 - val_accuracy: 0.6957\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9495 - accuracy: 0.8341 - val_loss: 1.1622 - val_accuracy: 0.6087\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9357 - accuracy: 0.7902 - val_loss: 1.1661 - val_accuracy: 0.6957\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9698 - accuracy: 0.8049 - val_loss: 1.1512 - val_accuracy: 0.6957\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9150 - accuracy: 0.8098 - val_loss: 1.1439 - val_accuracy: 0.6957\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8839 - accuracy: 0.8585 - val_loss: 1.1375 - val_accuracy: 0.6522\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9430 - accuracy: 0.8000 - val_loss: 1.1294 - val_accuracy: 0.6957\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9042 - accuracy: 0.8195 - val_loss: 1.1090 - val_accuracy: 0.6957\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8673 - accuracy: 0.8634 - val_loss: 1.1168 - val_accuracy: 0.7391\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8600 - accuracy: 0.8341 - val_loss: 1.1205 - val_accuracy: 0.7391\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8692 - accuracy: 0.8732 - val_loss: 1.1177 - val_accuracy: 0.6957\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8634 - accuracy: 0.8439 - val_loss: 1.1067 - val_accuracy: 0.6957\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8858 - accuracy: 0.8488 - val_loss: 1.0973 - val_accuracy: 0.6522\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8606 - accuracy: 0.8293 - val_loss: 1.0928 - val_accuracy: 0.7391\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8822 - accuracy: 0.8439 - val_loss: 1.0886 - val_accuracy: 0.7391\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8444 - accuracy: 0.8585 - val_loss: 1.0816 - val_accuracy: 0.7826\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8367 - accuracy: 0.8488 - val_loss: 1.0624 - val_accuracy: 0.7391\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8357 - accuracy: 0.8537 - val_loss: 1.0516 - val_accuracy: 0.7391\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8129 - accuracy: 0.8732 - val_loss: 1.0552 - val_accuracy: 0.7826\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8146 - accuracy: 0.8976 - val_loss: 1.0518 - val_accuracy: 0.6957\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8533 - accuracy: 0.8634 - val_loss: 1.0560 - val_accuracy: 0.7391\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7986 - accuracy: 0.9024 - val_loss: 1.0372 - val_accuracy: 0.7391\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7968 - accuracy: 0.8683 - val_loss: 1.0282 - val_accuracy: 0.7826\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7930 - accuracy: 0.8976 - val_loss: 1.0267 - val_accuracy: 0.8261\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7813 - accuracy: 0.8537 - val_loss: 1.0354 - val_accuracy: 0.7826\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7998 - accuracy: 0.8829 - val_loss: 1.0207 - val_accuracy: 0.7826\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8054 - accuracy: 0.8829 - val_loss: 1.0136 - val_accuracy: 0.7826\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7551 - accuracy: 0.8732 - val_loss: 1.0022 - val_accuracy: 0.8261\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7739 - accuracy: 0.8780 - val_loss: 1.0024 - val_accuracy: 0.8261\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7959 - accuracy: 0.8537 - val_loss: 1.0047 - val_accuracy: 0.7826\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7344 - accuracy: 0.8927 - val_loss: 0.9955 - val_accuracy: 0.7826\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7369 - accuracy: 0.9024 - val_loss: 0.9856 - val_accuracy: 0.8261\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7791 - accuracy: 0.8780 - val_loss: 0.9922 - val_accuracy: 0.8261\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7740 - accuracy: 0.8878 - val_loss: 0.9640 - val_accuracy: 0.8696\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7641 - accuracy: 0.8780 - val_loss: 0.9568 - val_accuracy: 0.8696\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7566 - accuracy: 0.8878 - val_loss: 0.9711 - val_accuracy: 0.8696\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7530 - accuracy: 0.8976 - val_loss: 0.9565 - val_accuracy: 0.8696\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7182 - accuracy: 0.8878 - val_loss: 0.9494 - val_accuracy: 0.8696\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7186 - accuracy: 0.8976 - val_loss: 0.9319 - val_accuracy: 0.8261\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7545 - accuracy: 0.9073 - val_loss: 0.9418 - val_accuracy: 0.8261\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6991 - accuracy: 0.9268 - val_loss: 0.9486 - val_accuracy: 0.8696\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7202 - accuracy: 0.8878 - val_loss: 0.9304 - val_accuracy: 0.8696\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7044 - accuracy: 0.8829 - val_loss: 0.9064 - val_accuracy: 0.8261\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6871 - accuracy: 0.9073 - val_loss: 0.9148 - val_accuracy: 0.8696\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7186 - accuracy: 0.9122 - val_loss: 0.9157 - val_accuracy: 0.8261\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7048 - accuracy: 0.8927 - val_loss: 0.8967 - val_accuracy: 0.8261\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.9171 - val_loss: 0.8901 - val_accuracy: 0.8696\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.9073 - val_loss: 0.8858 - val_accuracy: 0.8696\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6741 - accuracy: 0.9122 - val_loss: 0.8897 - val_accuracy: 0.8696\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7034 - accuracy: 0.9122 - val_loss: 0.8854 - val_accuracy: 0.8696\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6869 - accuracy: 0.8829 - val_loss: 0.8732 - val_accuracy: 0.8696\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.9024 - val_loss: 0.8657 - val_accuracy: 0.8696\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6475 - accuracy: 0.9366 - val_loss: 0.8600 - val_accuracy: 0.8696\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6507 - accuracy: 0.9268 - val_loss: 0.8556 - val_accuracy: 0.8696\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6459 - accuracy: 0.9171 - val_loss: 0.8540 - val_accuracy: 0.8696\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6491 - accuracy: 0.9220 - val_loss: 0.8435 - val_accuracy: 0.8696\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6095 - accuracy: 0.9317 - val_loss: 0.8461 - val_accuracy: 0.8696\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6359 - accuracy: 0.9122 - val_loss: 0.8642 - val_accuracy: 0.8696\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5928 - accuracy: 0.9415 - val_loss: 0.8391 - val_accuracy: 0.8696\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6249 - accuracy: 0.9220 - val_loss: 0.8085 - val_accuracy: 0.8696\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6132 - accuracy: 0.9415 - val_loss: 0.8103 - val_accuracy: 0.8696\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6171 - accuracy: 0.9317 - val_loss: 0.8255 - val_accuracy: 0.8696\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6118 - accuracy: 0.9220 - val_loss: 0.8033 - val_accuracy: 0.8696\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6020 - accuracy: 0.9415 - val_loss: 0.7971 - val_accuracy: 0.8696\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5849 - accuracy: 0.9317 - val_loss: 0.7959 - val_accuracy: 0.8696\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5756 - accuracy: 0.9366 - val_loss: 0.8083 - val_accuracy: 0.8696\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6101 - accuracy: 0.9366 - val_loss: 0.7989 - val_accuracy: 0.8696\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5703 - accuracy: 0.9366 - val_loss: 0.7966 - val_accuracy: 0.8696\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6132 - accuracy: 0.9317 - val_loss: 0.7849 - val_accuracy: 0.8696\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5720 - accuracy: 0.9366 - val_loss: 0.7848 - val_accuracy: 0.8696\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5712 - accuracy: 0.9317 - val_loss: 0.7725 - val_accuracy: 0.8696\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5657 - accuracy: 0.9512 - val_loss: 0.7686 - val_accuracy: 0.8696\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5528 - accuracy: 0.9561 - val_loss: 0.7709 - val_accuracy: 0.8696\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5363 - accuracy: 0.9415 - val_loss: 0.7610 - val_accuracy: 0.8696\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5364 - accuracy: 0.9561 - val_loss: 0.7571 - val_accuracy: 0.8696\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5435 - accuracy: 0.9659 - val_loss: 0.7587 - val_accuracy: 0.8696\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5658 - accuracy: 0.9561 - val_loss: 0.7518 - val_accuracy: 0.8696\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5259 - accuracy: 0.9415 - val_loss: 0.7470 - val_accuracy: 0.8696\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4993 - accuracy: 0.9463 - val_loss: 0.7358 - val_accuracy: 0.8696\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4967 - accuracy: 0.9659 - val_loss: 0.7521 - val_accuracy: 0.8696\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5062 - accuracy: 0.9659 - val_loss: 0.7686 - val_accuracy: 0.8696\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4628 - accuracy: 0.9707 - val_loss: 0.7369 - val_accuracy: 0.8696\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5127 - accuracy: 0.9610 - val_loss: 0.7231 - val_accuracy: 0.8696\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.9463 - val_loss: 0.7114 - val_accuracy: 0.8696\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4812 - accuracy: 0.9707 - val_loss: 0.7223 - val_accuracy: 0.8696\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.9561 - val_loss: 0.7167 - val_accuracy: 0.8696\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.9707 - val_loss: 0.7205 - val_accuracy: 0.8696\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5004 - accuracy: 0.9415 - val_loss: 0.7107 - val_accuracy: 0.8696\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4790 - accuracy: 0.9707 - val_loss: 0.6886 - val_accuracy: 0.8696\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5098 - accuracy: 0.9561 - val_loss: 0.6801 - val_accuracy: 0.8696\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.9707 - val_loss: 0.6943 - val_accuracy: 0.8696\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.9659 - val_loss: 0.6897 - val_accuracy: 0.8696\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4768 - accuracy: 0.9463 - val_loss: 0.6731 - val_accuracy: 0.8696\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4909 - accuracy: 0.9366 - val_loss: 0.6703 - val_accuracy: 0.8696\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4311 - accuracy: 0.9756 - val_loss: 0.6739 - val_accuracy: 0.8696\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4477 - accuracy: 0.9463 - val_loss: 0.6723 - val_accuracy: 0.8696\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4729 - accuracy: 0.9366 - val_loss: 0.6843 - val_accuracy: 0.8696\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4427 - accuracy: 0.9707 - val_loss: 0.6724 - val_accuracy: 0.8696\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4457 - accuracy: 0.9512 - val_loss: 0.6573 - val_accuracy: 0.8696\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4247 - accuracy: 0.9756 - val_loss: 0.6620 - val_accuracy: 0.8696\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.9610 - val_loss: 0.6613 - val_accuracy: 0.8696\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4092 - accuracy: 0.9902 - val_loss: 0.6479 - val_accuracy: 0.8696\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4271 - accuracy: 0.9659 - val_loss: 0.6570 - val_accuracy: 0.8696\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4164 - accuracy: 0.9561 - val_loss: 0.6582 - val_accuracy: 0.8696\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4573 - accuracy: 0.9659 - val_loss: 0.6432 - val_accuracy: 0.8696\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4291 - accuracy: 0.9561 - val_loss: 0.6372 - val_accuracy: 0.8696\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.9805 - val_loss: 0.6694 - val_accuracy: 0.8696\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4009 - accuracy: 0.9707 - val_loss: 0.6589 - val_accuracy: 0.8696\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3963 - accuracy: 0.9902 - val_loss: 0.6303 - val_accuracy: 0.8696\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4368 - accuracy: 0.9512 - val_loss: 0.6008 - val_accuracy: 0.8696\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.9805 - val_loss: 0.5957 - val_accuracy: 0.8696\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4092 - accuracy: 0.9610 - val_loss: 0.6300 - val_accuracy: 0.8696\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4118 - accuracy: 0.9610 - val_loss: 0.6674 - val_accuracy: 0.8696\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.9561 - val_loss: 0.6183 - val_accuracy: 0.8261\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3834 - accuracy: 0.9707 - val_loss: 0.5967 - val_accuracy: 0.8261\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.9805 - val_loss: 0.6065 - val_accuracy: 0.8696\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3752 - accuracy: 0.9707 - val_loss: 0.6050 - val_accuracy: 0.8696\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3910 - accuracy: 0.9707 - val_loss: 0.5920 - val_accuracy: 0.8696\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3842 - accuracy: 0.9805 - val_loss: 0.5896 - val_accuracy: 0.8696\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3707 - accuracy: 0.9756 - val_loss: 0.5966 - val_accuracy: 0.8696\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3775 - accuracy: 0.9805 - val_loss: 0.6028 - val_accuracy: 0.8696\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3687 - accuracy: 0.9659 - val_loss: 0.5894 - val_accuracy: 0.8696\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3572 - accuracy: 0.9854 - val_loss: 0.5829 - val_accuracy: 0.8696\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.9561 - val_loss: 0.5744 - val_accuracy: 0.8696\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3712 - accuracy: 0.9805 - val_loss: 0.5838 - val_accuracy: 0.8696\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3525 - accuracy: 0.9561 - val_loss: 0.5584 - val_accuracy: 0.8696\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.9805 - val_loss: 0.5643 - val_accuracy: 0.8696\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3752 - accuracy: 0.9610 - val_loss: 0.5824 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3330 - accuracy: 0.9805 - val_loss: 0.5635 - val_accuracy: 0.8696\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3450 - accuracy: 0.9805 - val_loss: 0.5454 - val_accuracy: 0.8696\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3666 - accuracy: 0.9659 - val_loss: 0.5523 - val_accuracy: 0.8696\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.9805 - val_loss: 0.5684 - val_accuracy: 0.8696\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3281 - accuracy: 0.9756 - val_loss: 0.5484 - val_accuracy: 0.8696\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3233 - accuracy: 0.9902 - val_loss: 0.5540 - val_accuracy: 0.8696\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3209 - accuracy: 0.9805 - val_loss: 0.5582 - val_accuracy: 0.8696\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3252 - accuracy: 0.9854 - val_loss: 0.5751 - val_accuracy: 0.8696\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3149 - accuracy: 0.9805 - val_loss: 0.5412 - val_accuracy: 0.8261\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3076 - accuracy: 0.9805 - val_loss: 0.5397 - val_accuracy: 0.8696\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2851 - accuracy: 0.9951 - val_loss: 0.5228 - val_accuracy: 0.8696\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3048 - accuracy: 0.9951 - val_loss: 0.5115 - val_accuracy: 0.8696\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3125 - accuracy: 0.9902 - val_loss: 0.5247 - val_accuracy: 0.8696\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2930 - accuracy: 0.9902 - val_loss: 0.5204 - val_accuracy: 0.8696\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3128 - accuracy: 0.9659 - val_loss: 0.5297 - val_accuracy: 0.8696\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3016 - accuracy: 0.9805 - val_loss: 0.5288 - val_accuracy: 0.8696\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3014 - accuracy: 0.9854 - val_loss: 0.5369 - val_accuracy: 0.8696\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 0.9805 - val_loss: 0.5158 - val_accuracy: 0.8696\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2967 - accuracy: 0.9854 - val_loss: 0.5262 - val_accuracy: 0.8696\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3002 - accuracy: 0.9854 - val_loss: 0.5259 - val_accuracy: 0.8696\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2807 - accuracy: 0.9902 - val_loss: 0.5039 - val_accuracy: 0.8696\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2973 - accuracy: 0.9854 - val_loss: 0.4950 - val_accuracy: 0.8696\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2903 - accuracy: 0.9756 - val_loss: 0.4769 - val_accuracy: 0.8696\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2521 - accuracy: 0.9902 - val_loss: 0.4727 - val_accuracy: 0.8696\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2648 - accuracy: 0.9902 - val_loss: 0.4931 - val_accuracy: 0.9130\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2706 - accuracy: 0.9805 - val_loss: 0.4992 - val_accuracy: 0.8696\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2642 - accuracy: 0.9902 - val_loss: 0.4778 - val_accuracy: 0.8696\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8696\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2537 - accuracy: 0.9951 - val_loss: 0.4893 - val_accuracy: 0.9130\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2502 - accuracy: 0.9902 - val_loss: 0.4696 - val_accuracy: 0.8696\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2518 - accuracy: 0.9951 - val_loss: 0.4724 - val_accuracy: 0.8696\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2675 - accuracy: 0.9902 - val_loss: 0.4730 - val_accuracy: 0.9130\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2656 - accuracy: 0.9951 - val_loss: 0.4725 - val_accuracy: 0.8696\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2615 - accuracy: 0.9902 - val_loss: 0.4599 - val_accuracy: 0.9130\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2695 - accuracy: 0.9707 - val_loss: 0.4575 - val_accuracy: 0.8696\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2656 - accuracy: 0.9756 - val_loss: 0.4618 - val_accuracy: 0.9130\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2622 - accuracy: 0.9854 - val_loss: 0.4810 - val_accuracy: 0.9130\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2644 - accuracy: 0.9951 - val_loss: 0.4592 - val_accuracy: 0.8696\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2640 - accuracy: 0.9756 - val_loss: 0.4447 - val_accuracy: 0.8696\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9130\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2468 - accuracy: 0.9854 - val_loss: 0.4435 - val_accuracy: 0.9130\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8696\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2430 - accuracy: 0.9951 - val_loss: 0.4505 - val_accuracy: 0.8696\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2267 - accuracy: 0.9951 - val_loss: 0.4525 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS),\n",
    "    loss='categorical_crossentropy', metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Image loading...\n",
      "Image loading done! Starting train set creation...\n",
      "Train set creation done!\n"
     ]
    }
   ],
   "source": [
    "print('Starting Image loading...')\n",
    "reduced = True\n",
    "label_map = {label: num for num, label in enumerate(movements)}\n",
    "sequences, labels = [], []\n",
    "for movement in movements:\n",
    "    for dirpath, dirnames, files in os.walk(os.path.join(root, movement)):\n",
    "        sequence = []\n",
    "        if len(files) != 0:\n",
    "            if reduced:\n",
    "                for i in range(sequence_length):\n",
    "                    if i % 4 == 0:\n",
    "                        img = cv2.imread(os.path.join(dirpath, '{}.png'.format(i)))\n",
    "                        sequence.append(img)\n",
    "            else:\n",
    "                for i in range(sequence_length):\n",
    "                    img = cv2.imread(os.path.join(dirpath, '{}.png'.format(i)))\n",
    "                    sequence.append(img)\n",
    "        if len(sequence) > 0:\n",
    "            sequences.append(sequence)\n",
    "            labels.append(label_map[movement])\n",
    "print('Image loading done! Starting train set creation...')\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_value)\n",
    "print('Train set creation done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_15 (Conv3D)           (None, 8, 118, 157, 16)   1744      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 4, 59, 78, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 4, 59, 78, 32)     13856     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 2, 29, 39, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 29, 39, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 2, 29, 39, 16)     13840     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 1, 14, 19, 16)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 14, 19, 16)     64        \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4256)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4256)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                212850    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 243,628\n",
      "Trainable params: 243,532\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 195s 20s/step - loss: 2.6862 - accuracy: 0.1538 - val_loss: 8.3273 - val_accuracy: 0.1665\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 186s 19s/step - loss: 2.4897 - accuracy: 0.1987 - val_loss: 5.8408 - val_accuracy: 0.1633\n"
     ]
    }
   ],
   "source": [
    "model_vid = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv3D(16, kernel_size=(3, 3, 4), input_shape=(10, 120, 160, 3), strides=(1, 1, 1),\n",
    "                      padding='valid',\n",
    "                      activation='relu'),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.Conv3D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv3D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(20, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(6, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "model_vid.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INIT_LR, decay=INIT_LR / 2),\n",
    "    loss='categorical_crossentropy', metrics=[\"accuracy\"],\n",
    ")\n",
    "model_vid.summary()\n",
    "history = model_vid.fit(X_train, y_train, epochs=2, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load('test_training_history.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'loss': [2.6862385272979736, 2.489744186401367], 'accuracy': [0.1538461595773697, 0.19871795177459717], 'val_loss': [8.327266693115234, 5.840782165527344], 'val_accuracy': [0.1665332317352295, 0.16333065927028656]},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'test'\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig(f'{name}_accuracy_results.png')\n",
    "plt.clf();\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(f'{name}_loss_results.png')\n",
    "np.save(f'{name}_training_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 118, 157, 128)     4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 59, 78, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 59, 78, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 59, 78, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 29, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 29, 39, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8512)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               1702600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 1,830,206\n",
      "Trainable params: 1,830,078\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rgb = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(128, kernel_size=(3, 4), input_shape=(120, 160, 3), strides=(1, 1), padding='valid',\n",
    "                      activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_rgb.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS),\n",
    "    loss='categorical_crossentropy', metrics=[\"accuracy\"],\n",
    ")\n",
    "model_rgb.summary()\n",
    "model_rgb.load_weights('rgb_only_new_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_rgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10911"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted : 4. Real : 4\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(f'predicted : {np.argmax(res[i])}. Real : {np.argmax(y_val[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9593987718815874"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(len(y_train)):\n",
    "    if np.argmax(res[i]) == np.argmax(y_train[i]):\n",
    "        counter = counter + 1\n",
    "counter = counter / len(y_train)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load('test2/rgb/scroll_down/2021-10-14-103320_0/5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}